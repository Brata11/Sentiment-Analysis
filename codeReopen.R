tweets<-searchTwitter("reopen",n=10000,lang="en")
tweets
tweetsdf<-twListToDF(tweets)
write.csv(tweetsdf,file='Reopen Sentiment',row.names=F)
reopen<-read.csv(file.choose(),header=T)
str(reopen)
library(tm)
corpus<-iconv(reopen$text,to="utf-8")
corpus<-Corpus(VectorSource(corpus))
inspect(corpus[1:10])
corpus<-tm_map(corpus,tolower)
corpus<-tm_map(corpus,removePunctuation)
corpus<-tm_map(corpus,removeNumbers)
cleanset<-tm_map(corpus,removeWords,stopwords('english'))
removeURL<-function(x)gsub('http[[:alnum:]]*','',x)
cleanset<-tm_map(cleanset,content_transformer(removeURL))
cleanset<-tm_map(cleanset,stripWhitespace)
tdm<-TermDocumentMatrix(cleanset)
tdm
tdm<-as.matrix(tdm)
tdm[1:10,1:10]
a<-rowSums(tdm)
a
barplot(w)
barplot(a,las=2,col=rainbow(50))
library(wordcloud)
a<-sort(rowSums(tdm),decreasing= TRUE)
set.seed(222)
wordcloud(words=names(a),freq=a)
wordcloud(words=names(a),freq=a,min.freq=1,colors=brewer.pal(8,'Dark2'),scale=c(3,0.5))
library(wordcloud2)
wordcloud(a,size=0.5,shape='circle')
a<-data.frame(names(a),a)
colnames(a)<-c('word','freq')
wordcloud2(a,size=0.5,shape='circle')
library(syuzhet)
library(lubridate)
library(ggplot2)
library(scales)
library(reshape2)
library(dplyr)
library(syuzhet)
library(lubridate)
library(ggplot2)
library(scales)
library(reshape2)
library(dplyr)
covvac<-read.csv(file.choose(),header=T)
tweet<-iconv(covvac$text,to='utf-8')
sentiscore<-get_nrc_sentiment(tweet)
head(sentiscore)
barplot(colSums(sentiscore),las=2,col=rainbow(10),ylab='Count',main='Sentiment Scores for Reopening Economy')
wordcloud(words=names(a),freq=a,min.freq=50,colors=brewer.pal(8,'Dark2'),scale=c(3,0.5))
wordcloud(words=names(a),freq=a)
wordcloud(words=names(a),freq=a,max.freq=150,colors=brewer.pal(8,'Dark2'))

